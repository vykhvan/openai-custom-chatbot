{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "124e5672",
   "metadata": {},
   "source": [
    "# Custom Chatbot Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4a94b3",
   "metadata": {},
   "source": [
    "TODO: In this cell, write an explanation of which dataset you have chosen and why it is appropriate for this task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63d4c5f",
   "metadata": {},
   "source": [
    "## Data Wrangling\n",
    "\n",
    "TODO: In the cells below, load your chosen dataset into a `pandas` dataframe with a column named `\"text\"`. This column should contain all of your text data, separated into at least 20 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b839592c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openai\n",
    "from openai.embeddings_utils import get_embedding, distances_from_embeddings\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "530f95d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"...\"\n",
    "EMBEDDING_MODEL_NAME = \"text-embedding-ada-002\"\n",
    "COMPLETION_MODEL_NAME = \"gpt-3.5-turbo-instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dd26292",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(df: pd.DataFrame) -> list:\n",
    "    \"\"\"\n",
    "    Generate text from DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input DataFrame containing URL, Trends, and Source columns.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of strings containing text generated from the DataFrame.\n",
    "    \"\"\"\n",
    "    text = []\n",
    "    for _, row in df.iterrows():\n",
    "        text.append(\"URL: \" + row[\"URL\"] + \"\\n\" \n",
    "                              + \"Trends: \" + row[\"Trends\"] + \"\\n\"\n",
    "                              + \"Source: \" + row[\"Source\"])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b2adc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(df: pd.DataFrame, batch_size: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate embeddings for text data in DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input DataFrame containing text data.\n",
    "        batch_size (int): Batch size for generating embeddings.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with 'embeddings' column containing generated embeddings.\n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "    df[\"text\"] = get_text(df)\n",
    "    for i in range(0, len(df), batch_size):\n",
    "        response = openai.Embedding.create(\n",
    "            input=df.iloc[i:i+batch_size][\"text\"].tolist(),\n",
    "            engine=EMBEDDING_MODEL_NAME\n",
    "        )\n",
    "\n",
    "        embeddings.extend([data['embedding'] for data in response[\"data\"]])\n",
    "\n",
    "    df['embeddings'] = embeddings\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb979575",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rag_database() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a RAG (Retrieval-Augmented Generation) database.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing RAG database with text embeddings.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv('data/2023_fashion_trends.csv')\n",
    "    df = get_embeddings(df, 5)\n",
    "    df.to_csv('fashion_trends_embeddings.csv', index=False)\n",
    "    return df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d074660a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Trends</th>\n",
       "      <th>Source</th>\n",
       "      <th>text</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.refinery29.com/en-us/fashion-trend...</td>\n",
       "      <td>2023 Fashion Trend: Red. Glossy red hues took ...</td>\n",
       "      <td>7 Fashion Trends That Will Take Over 2023 — Sh...</td>\n",
       "      <td>URL: https://www.refinery29.com/en-us/fashion-...</td>\n",
       "      <td>[-0.012282825075089931, -0.023432452231645584,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.refinery29.com/en-us/fashion-trend...</td>\n",
       "      <td>2023 Fashion Trend: Cargo Pants. Utilitarian w...</td>\n",
       "      <td>7 Fashion Trends That Will Take Over 2023 — Sh...</td>\n",
       "      <td>URL: https://www.refinery29.com/en-us/fashion-...</td>\n",
       "      <td>[-0.0002861183893401176, -0.03149326890707016,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.refinery29.com/en-us/fashion-trend...</td>\n",
       "      <td>2023 Fashion Trend: Sheer Clothing. \"Bare it a...</td>\n",
       "      <td>7 Fashion Trends That Will Take Over 2023 — Sh...</td>\n",
       "      <td>URL: https://www.refinery29.com/en-us/fashion-...</td>\n",
       "      <td>[-0.006564814131706953, -0.022983480244874954,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.refinery29.com/en-us/fashion-trend...</td>\n",
       "      <td>2023 Fashion Trend: Denim Reimagined. From dou...</td>\n",
       "      <td>7 Fashion Trends That Will Take Over 2023 — Sh...</td>\n",
       "      <td>URL: https://www.refinery29.com/en-us/fashion-...</td>\n",
       "      <td>[-0.00231093168258667, -0.0138161052018404, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.refinery29.com/en-us/fashion-trend...</td>\n",
       "      <td>2023 Fashion Trend: Shine For The Daytime. The...</td>\n",
       "      <td>7 Fashion Trends That Will Take Over 2023 — Sh...</td>\n",
       "      <td>URL: https://www.refinery29.com/en-us/fashion-...</td>\n",
       "      <td>[0.00034107582177966833, 0.0012216639006510377...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 URL  \\\n",
       "0  https://www.refinery29.com/en-us/fashion-trend...   \n",
       "1  https://www.refinery29.com/en-us/fashion-trend...   \n",
       "2  https://www.refinery29.com/en-us/fashion-trend...   \n",
       "3  https://www.refinery29.com/en-us/fashion-trend...   \n",
       "4  https://www.refinery29.com/en-us/fashion-trend...   \n",
       "\n",
       "                                              Trends  \\\n",
       "0  2023 Fashion Trend: Red. Glossy red hues took ...   \n",
       "1  2023 Fashion Trend: Cargo Pants. Utilitarian w...   \n",
       "2  2023 Fashion Trend: Sheer Clothing. \"Bare it a...   \n",
       "3  2023 Fashion Trend: Denim Reimagined. From dou...   \n",
       "4  2023 Fashion Trend: Shine For The Daytime. The...   \n",
       "\n",
       "                                              Source  \\\n",
       "0  7 Fashion Trends That Will Take Over 2023 — Sh...   \n",
       "1  7 Fashion Trends That Will Take Over 2023 — Sh...   \n",
       "2  7 Fashion Trends That Will Take Over 2023 — Sh...   \n",
       "3  7 Fashion Trends That Will Take Over 2023 — Sh...   \n",
       "4  7 Fashion Trends That Will Take Over 2023 — Sh...   \n",
       "\n",
       "                                                text  \\\n",
       "0  URL: https://www.refinery29.com/en-us/fashion-...   \n",
       "1  URL: https://www.refinery29.com/en-us/fashion-...   \n",
       "2  URL: https://www.refinery29.com/en-us/fashion-...   \n",
       "3  URL: https://www.refinery29.com/en-us/fashion-...   \n",
       "4  URL: https://www.refinery29.com/en-us/fashion-...   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [-0.012282825075089931, -0.023432452231645584,...  \n",
       "1  [-0.0002861183893401176, -0.03149326890707016,...  \n",
       "2  [-0.006564814131706953, -0.022983480244874954,...  \n",
       "3  [-0.00231093168258667, -0.0138161052018404, 0....  \n",
       "4  [0.00034107582177966833, 0.0012216639006510377...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_rag_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae769871",
   "metadata": {},
   "source": [
    "## Custom Query Completion\n",
    "\n",
    "TODO: In the cells below, compose a custom query using your chosen dataset and retrieve results from an OpenAI `Completion` model. You may copy and paste any useful code from the course materials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d2b8fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rag_database() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load the RAG (Retrieval-Augmented Generation) database.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing RAG database with text embeddings.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(\"fashion_trends_embeddings.csv\")\n",
    "    df[\"embeddings\"] = df[\"embeddings\"].apply(eval).apply(np.array)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "582f0656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rows_sorted_by_relevance(question: str, df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function that takes in a question string and a dataframe containing\n",
    "    rows of text and associated embeddings, and returns that dataframe\n",
    "    sorted from least to most relevant for that question\n",
    "\n",
    "    Parameters:\n",
    "        question (str): The question for relevance sorting.\n",
    "        df (pd.DataFrame): DataFrame containing text and associated embeddings.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame sorted by relevance to the question.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get embeddings for the question text\n",
    "    question_embeddings = get_embedding(question, engine=EMBEDDING_MODEL_NAME)\n",
    "    \n",
    "    # Make a copy of the dataframe and add a \"distances\" column containing\n",
    "    # the cosine distances between each row's embeddings and the\n",
    "    # embeddings of the question\n",
    "    df_copy = df.copy()\n",
    "    df_copy[\"distances\"] = distances_from_embeddings(\n",
    "        question_embeddings,\n",
    "        df_copy[\"embeddings\"].values,\n",
    "        distance_metric=\"cosine\"\n",
    "    )\n",
    "    \n",
    "    # Sort the copied dataframe by the distances and return it\n",
    "    # (shorter distance = more relevant so we sort in ascending order)\n",
    "    df_copy.sort_values(\"distances\", ascending=True, inplace=True)\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "951b2872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(question: str, df: pd.DataFrame, max_token_count: int) -> str:\n",
    "    \"\"\"\n",
    "    Given a question and a dataframe containing rows of text and their\n",
    "    embeddings, return a text prompt to send to a Completion model\n",
    "\n",
    "    Parameters:\n",
    "        question (str): The question to be answered based on the context.\n",
    "        df (pd.DataFrame): DataFrame containing text and associated embeddings.\n",
    "        max_token_count (int): Maximum token count for the generated prompt.\n",
    "\n",
    "    Returns:\n",
    "        str: Text prompt for the question and context.\n",
    "    \"\"\"\n",
    "    # Create a tokenizer that is designed to align with our embeddings\n",
    "    tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    \n",
    "    # Count the number of tokens in the prompt template and question\n",
    "    prompt_template = \"\"\"\n",
    "Answer the question based on the context below, and if the question\n",
    "can't be answered based on the context, say \"I don't know\"\n",
    "\n",
    "Context: \n",
    "\n",
    "{}\n",
    "\n",
    "---\n",
    "\n",
    "Question: {}\n",
    "Answer:\"\"\"\n",
    "    \n",
    "    current_token_count = len(tokenizer.encode(prompt_template)) + \\\n",
    "                            len(tokenizer.encode(question))\n",
    "    \n",
    "    context = []\n",
    "    for text in get_rows_sorted_by_relevance(question, df)[\"text\"].values:\n",
    "        \n",
    "        # Increase the counter based on the number of tokens in this row\n",
    "        text_token_count = len(tokenizer.encode(text))\n",
    "        current_token_count += text_token_count\n",
    "        \n",
    "        # Add the row of text to the list if we haven't exceeded the max\n",
    "        if current_token_count <= max_token_count:\n",
    "            context.append(text)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return prompt_template.format(\"\\n\\n###\\n\\n\".join(context), question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "635b1f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(\n",
    "    question: str, \n",
    "    df: pd.DataFrame, \n",
    "    max_prompt_tokens: int = 3000, \n",
    "    max_answer_tokens: int = 300\n",
    "):\n",
    "    \"\"\"\n",
    "    Given a question, a dataframe containing rows of text, and a maximum\n",
    "    number of desired tokens in the prompt and response, return the\n",
    "    answer to the question according to an OpenAI Completion model\n",
    "    \n",
    "    If the model produces an error, return an empty string\n",
    "\n",
    "    Parameters:\n",
    "        question (str): The question to be answered.\n",
    "        df (pd.DataFrame): DataFrame containing text and associated embeddings.\n",
    "        max_prompt_tokens (int): Maximum token count for the generated prompt.\n",
    "        max_answer_tokens (int): Maximum token count for the model's response.\n",
    "\n",
    "    Returns:\n",
    "        str: Answer to the question generated by the Completion model.\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = create_prompt(question, df, max_prompt_tokens)\n",
    "    \n",
    "    try:\n",
    "        response = openai.Completion.create(\n",
    "            model=COMPLETION_MODEL_NAME,\n",
    "            prompt=prompt,\n",
    "            max_tokens=max_answer_tokens\n",
    "        )\n",
    "        return response[\"choices\"][0][\"text\"].strip()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f63c9e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Trends</th>\n",
       "      <th>Source</th>\n",
       "      <th>text</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.refinery29.com/en-us/fashion-trend...</td>\n",
       "      <td>2023 Fashion Trend: Red. Glossy red hues took ...</td>\n",
       "      <td>7 Fashion Trends That Will Take Over 2023 — Sh...</td>\n",
       "      <td>URL: https://www.refinery29.com/en-us/fashion-...</td>\n",
       "      <td>[-0.012282825075089931, -0.023432452231645584,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.refinery29.com/en-us/fashion-trend...</td>\n",
       "      <td>2023 Fashion Trend: Cargo Pants. Utilitarian w...</td>\n",
       "      <td>7 Fashion Trends That Will Take Over 2023 — Sh...</td>\n",
       "      <td>URL: https://www.refinery29.com/en-us/fashion-...</td>\n",
       "      <td>[-0.0002861183893401176, -0.03149326890707016,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.refinery29.com/en-us/fashion-trend...</td>\n",
       "      <td>2023 Fashion Trend: Sheer Clothing. \"Bare it a...</td>\n",
       "      <td>7 Fashion Trends That Will Take Over 2023 — Sh...</td>\n",
       "      <td>URL: https://www.refinery29.com/en-us/fashion-...</td>\n",
       "      <td>[-0.006564814131706953, -0.022983480244874954,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.refinery29.com/en-us/fashion-trend...</td>\n",
       "      <td>2023 Fashion Trend: Denim Reimagined. From dou...</td>\n",
       "      <td>7 Fashion Trends That Will Take Over 2023 — Sh...</td>\n",
       "      <td>URL: https://www.refinery29.com/en-us/fashion-...</td>\n",
       "      <td>[-0.00231093168258667, -0.0138161052018404, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.refinery29.com/en-us/fashion-trend...</td>\n",
       "      <td>2023 Fashion Trend: Shine For The Daytime. The...</td>\n",
       "      <td>7 Fashion Trends That Will Take Over 2023 — Sh...</td>\n",
       "      <td>URL: https://www.refinery29.com/en-us/fashion-...</td>\n",
       "      <td>[0.00034107582177966833, 0.0012216639006510377...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 URL  \\\n",
       "0  https://www.refinery29.com/en-us/fashion-trend...   \n",
       "1  https://www.refinery29.com/en-us/fashion-trend...   \n",
       "2  https://www.refinery29.com/en-us/fashion-trend...   \n",
       "3  https://www.refinery29.com/en-us/fashion-trend...   \n",
       "4  https://www.refinery29.com/en-us/fashion-trend...   \n",
       "\n",
       "                                              Trends  \\\n",
       "0  2023 Fashion Trend: Red. Glossy red hues took ...   \n",
       "1  2023 Fashion Trend: Cargo Pants. Utilitarian w...   \n",
       "2  2023 Fashion Trend: Sheer Clothing. \"Bare it a...   \n",
       "3  2023 Fashion Trend: Denim Reimagined. From dou...   \n",
       "4  2023 Fashion Trend: Shine For The Daytime. The...   \n",
       "\n",
       "                                              Source  \\\n",
       "0  7 Fashion Trends That Will Take Over 2023 — Sh...   \n",
       "1  7 Fashion Trends That Will Take Over 2023 — Sh...   \n",
       "2  7 Fashion Trends That Will Take Over 2023 — Sh...   \n",
       "3  7 Fashion Trends That Will Take Over 2023 — Sh...   \n",
       "4  7 Fashion Trends That Will Take Over 2023 — Sh...   \n",
       "\n",
       "                                                text  \\\n",
       "0  URL: https://www.refinery29.com/en-us/fashion-...   \n",
       "1  URL: https://www.refinery29.com/en-us/fashion-...   \n",
       "2  URL: https://www.refinery29.com/en-us/fashion-...   \n",
       "3  URL: https://www.refinery29.com/en-us/fashion-...   \n",
       "4  URL: https://www.refinery29.com/en-us/fashion-...   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [-0.012282825075089931, -0.023432452231645584,...  \n",
       "1  [-0.0002861183893401176, -0.03149326890707016,...  \n",
       "2  [-0.006564814131706953, -0.022983480244874954,...  \n",
       "3  [-0.00231093168258667, -0.0138161052018404, 0....  \n",
       "4  [0.00034107582177966833, 0.0012216639006510377...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_rag_database()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1783f146",
   "metadata": {},
   "source": [
    "## Custom Performance Demonstration\n",
    "\n",
    "TODO: In the cells below, demonstrate the performance of your custom query using at least 2 questions. For each question, show the answer from a basic `Completion` model query as well as the answer from your custom query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f11fdc0",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4901c850",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What was the fashion trend in spring 2023?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f0a61e",
   "metadata": {},
   "source": [
    "#### Basic Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8d051f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, I cannot predict fashion trends for future years.\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "    model=COMPLETION_MODEL_NAME, \n",
    "    prompt=question, \n",
    "    max_tokens=300)\n",
    "\n",
    "print(response[\"choices\"][0][\"text\"].strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1c55b9",
   "metadata": {},
   "source": [
    "#### Custom Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4e5a435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fashion trends for spring 2023 included more 3D designs with floral motifs, bold colors and bold prints, minimalist and simple styles, edgy and grunge styles, delicate and sheer fabrics, balloon and puffed shapes, tailored and tailored looks, metallic fabrics and neons, and a return to '90s and '00s fashion. The specific trends mentioned vary among sources.\n"
     ]
    }
   ],
   "source": [
    "answer = answer_question(question, df)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e86e37c",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f646989",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What was the fashion trend in autumn 2023?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a5bce5",
   "metadata": {},
   "source": [
    "#### Basic Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "514ec253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is impossible to predict fashion trends of a specific year in the future. Fashion trends are constantly changing and evolving and are influenced by various factors such as societal changes, cultural influences, and designer creativity. It is best to follow current fashion trends and make your own unique style choices.\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "    model=COMPLETION_MODEL_NAME, \n",
    "    prompt=question, \n",
    "    max_tokens=300)\n",
    "\n",
    "print(response[\"choices\"][0][\"text\"].strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bac884",
   "metadata": {},
   "source": [
    "#### Custom Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "11c07a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metallics were commonplace in autumn/winter collections.\n"
     ]
    }
   ],
   "source": [
    "answer = answer_question(question, df)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8fd7fa",
   "metadata": {},
   "source": [
    "The fashion trends dataset has been chosen for Custom Fashion Chatbot."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
